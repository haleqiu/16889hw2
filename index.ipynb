{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.1\n",
    "* Fitted voxel\n",
    "\n",
    "predicted voxel             |  ground truth voxel\n",
    ":-------------------------:|:-------------------------:\n",
    "![Alt Text](image/voxel_predict.gif)  |  ![Alt Text](image/voxel_gt.gif)\n",
    "\n",
    "# Q1.2\n",
    "predicted mesh             |  ground truth mesh\n",
    ":-------------------------:|:-------------------------:\n",
    "![Alt Text](image/mesh_predict.gif) | ![Alt Text](image/mesh_gt.gif)\n",
    "\n",
    "# Q1.3\n",
    "\n",
    "predicted point             |  ground truth mesh\n",
    ":-------------------------:|:-------------------------:\n",
    "![Alt Text](image/point_predict.gif) | ![Alt Text](image/point_gt.gif)\n",
    "\n",
    "# Q2.1\n",
    "predicted voxel             |  ground truth voxel | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.1_vox1.gif)  |  ![Alt Text](image/2.1_voxgt1.gif) | [<img src=\"image/image0.png\" width=\"250\"/>](image/image0.png)\n",
    "\n",
    "predicted voxel             |  ground truth voxel | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.1_vox2.gif)  |  ![Alt Text](image/2.1_voxgt2.gif) | [<img src=\"image/image10.png\" width=\"250\"/>](image/image10.png)\n",
    "\n",
    "predicted voxel             |  ground truth voxel | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.1_vox3.gif)  |  ![Alt Text](image/2.1_voxgt3.gif) | [<img src=\"image/image120.png\" width=\"250\"/>](image/image120.png)\n",
    "\n",
    "# Q2.2\n",
    "predicted point             |  ground truth point | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.2_point1.gif)  |  ![Alt Text](image/2.2_pointgt1.gif) | [<img src=\"image/image0.png\" width=\"250\"/>](image/image0.png)\n",
    "\n",
    "predicted point             |  ground truth point | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.2_point2.gif)  |  ![Alt Text](image/2.2_pointgt2.gif) | [<img src=\"image/image10.png\" width=\"250\"/>](image/image10.png)\n",
    "\n",
    "predicted point             |  ground truth point | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.2_point3.gif)  |  ![Alt Text](image/2.2_pointgt3.gif) | [<img src=\"image/image120.png\" width=\"250\"/>](image/image120.png)\n",
    "\n",
    "# Q2.3\n",
    "\n",
    "predicted point             |  ground truth point | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.3_mesh1.gif)  |  ![Alt Text](image/2.3_meshgt1.gif) | [<img src=\"image/image0.png\" width=\"250\"/>](image/image0.png)\n",
    "\n",
    "predicted point             |  ground truth point | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.3_mesh2.gif)  |  ![Alt Text](image/2.3_meshgt2.gif) | [<img src=\"image/image10.png\" width=\"250\"/>](image/image10.png)\n",
    "\n",
    "predicted point             |  ground truth point | image\n",
    ":-------------------------:|:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/2.3_mesh3.gif)  |  ![Alt Text](image/2.3_meshgt3.gif) | [<img src=\"image/image120.png\" width=\"250\"/>](image/image120.png)\n",
    "\n",
    "# Q2.4\n",
    "\n",
    "|   model    | vox | point  | mesh|\n",
    "| :---        |    :----:   |          :---: |           :---: |\n",
    "| F1 score   |   88.18633  |   87.98031 |  88.85673 |\n",
    "\n",
    "# Q2.5\n",
    "\n",
    "I evaluate the change on `n_points`. Ideally increasing the number of `n_points` can contribute to a more accurate 3D model, but this may not always be true. When we increase the `n_points` the output channels of the last fully connected layer will also increase. When the `n_points` is higher than a threshold. It may have 2 issues, First, more computation is needed to train the network. Second, increasing the number of sampling points may not always provide more supervision on the model. \n",
    "   \n",
    "| num of points | 2048 | 4096 | 6144 |\n",
    "| :---        |    :----:   |          :---: |           :---: |\n",
    "| F1 score   | 85.09808        |   87.98031    |  87.043495 |\n",
    "<!-- | visualization | ![Alt Text](image/2.3_mesh3.gif)  |  ![Alt Text](image/2.3_meshgt3.gif) | [<img src=\"image/image120.png\" width=\"250\"/>](image/image120.png) -->\n",
    "\n",
    "# Q2.6\n",
    "\n",
    "One things that is interesting to see, is the process of how the model learn gradually during the training process. So I plot the visualization result of the voxel net during the training. \n",
    "\n",
    "without training             |  200 iterations | 400 iterations | 2000 iterations\n",
    ":-------------------------:|:-------------------------: |:-------------------------: |:-------------------------:\n",
    "![Alt Text](image/0_point.gif)  |  ![Alt Text](image/200_point.gif) | ![Alt Text](train_process/400_point.gif) | ![Alt Text](image/2000_point.gif)\n",
    "\n",
    "Without training the model, the point cloud looks is noise don't have any useful information. After 200 iterations, the model start to learn the structure of the chair. With 400 iterations, the model learn some detailed information like how the foot and armrest of the chair should be. After 2000 iterations, the model removes some outliers and the all voxels estimated are in the range of the object.\n",
    "\n",
    "### encoded feature\n",
    "Another interesting things I wanna explore is the meaning of the feature channels in the encoded feature after resnet. I compare the encoded feature from the chair and sofa as below.\n",
    "\n",
    "![Alt Text](image/encoded_feature.png)\n",
    "\n",
    "sofa chair        |  chair |\n",
    ":-------------------------:|:-------------------------: |\n",
    "![Alt Text](image/sofa_vox.gif)  |  ![Alt Text](image/chair_vox.gif) |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
